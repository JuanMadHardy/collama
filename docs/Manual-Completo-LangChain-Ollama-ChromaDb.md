# ðŸ“˜ **Manual Completo: LangChain + Ollama + ChromaDB**
### *DocumentaciÃ³n oficial para desarrolladores junior y mid-level*

---

# 1. IntroducciÃ³n

Este manual describe cÃ³mo construir aplicaciones de IA **locales, privadas y escalables** utilizando:

- **LangChain** â†’ Framework para orquestaciÃ³n de LLMs
- **Ollama** â†’ Servidor local de modelos
- **ChromaDB** â†’ Base vectorial local para RAG

El objetivo es que cualquier desarrollador del equipo pueda:

- Entender la arquitectura
- Crear pipelines de RAG
- Construir agentes
- Mantener proyectos reales en producciÃ³n local

---

# 2. Arquitectura General

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        Usuario           â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   LangChain     â”‚
                    â”‚  (OrquestaciÃ³n) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                   â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prompting    â”‚   â”‚  Ollama LLM    â”‚   â”‚   ChromaDB        â”‚
â”‚ Templates    â”‚   â”‚ (Inferencia)   â”‚   â”‚ (Vector Store)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# 3. InstalaciÃ³n y ConfiguraciÃ³n

## 3.1 Requisitos

- Ubuntu 25
- Python 3.10+
- 8GB RAM mÃ­nimo
- GPU opcional (recomendado)

## 3.2 Crear entorno virtual

```bash
python3 -m venv venv
source venv/bin/activate
```

## 3.3 Instalar LangChain

```bash
pip install langchain langchain-community langchain-ollama
```

## 3.4 Instalar Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Verificar:

```bash
ollama list
```

## 3.5 Instalar ChromaDB

```bash
pip install chromadb
```

---

# 4. Primeros Pasos

## 4.1 Tu primer LLM local

```python
from langchain_ollama import ChatOllama

llm = ChatOllama(model="mistral")
print(llm.invoke("Hola, Â¿quÃ© puedes hacer?"))
```

## 4.2 Primer Prompt Template

```python
from langchain.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages([
    ("system", "Eres un asistente tÃ©cnico."),
    ("user", "{pregunta}")
])
```

## 4.3 Primera Chain

```python
chain = prompt | llm
print(chain.invoke({"pregunta": "Explica quÃ© es LangChain"}))
```

---

# 5. Document Loaders

LangChain soporta loaders para:

- PDF
- Markdown
- HTML
- DOCX
- TXT

Ejemplo:

```python
from langchain.document_loaders import TextLoader

docs = TextLoader("manual.txt").load()
```

---

# 6. Chunking y Preprocesado

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)

chunks = splitter.split_documents(docs)
```

---

# 7. Embeddings Locales con Ollama

```python
from langchain_ollama import OllamaEmbeddings

embeddings = OllamaEmbeddings(model="mistral")
```

---

# 8. ChromaDB en Profundidad

## 8.1 Crear base vectorial

```python
from langchain.vectorstores import Chroma

db = Chroma.from_documents(
    chunks,
    embeddings,
    persist_directory="db"
)
```

## 8.2 RecuperaciÃ³n

```python
retriever = db.as_retriever()
result = retriever.get_relevant_documents("Â¿CÃ³mo configuro el sistema?")
```

---

# 9. ConstrucciÃ³n de un RAG Completo

```python
from langchain.chains import RetrievalQA

qa = RetrievalQA.from_chain_type(
    llm=ChatOllama(model="mistral"),
    retriever=retriever,
    chain_type="stuff"
)

print(qa.invoke("Explica el contenido del manual"))
```

---

# 10. Agentes y Herramientas

## 10.1 Crear herramienta personalizada

```python
from langchain.tools import tool

@tool
def contar_palabras(texto: str) -> int:
    return len(texto.split())
```

## 10.2 Crear agente

```python
from langchain.agents import initialize_agent, AgentType

agent = initialize_agent(
    tools=[contar_palabras],
    llm=ChatOllama(model="mistral"),
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION
)

agent.invoke("Cuenta las palabras de: Hola mundo desde LangChain")
```

---

# 11. Patrones de DiseÃ±o Recomendados

- Separar prompts en `/prompts`
- Separar chains en `/chains`
- Separar agentes en `/agents`
- Mantener loaders en `/loaders`
- Persistir ChromaDB en `/db`
- Versionar modelos Ollama

---

# 12. Seguridad y Privacidad

- No mezclar datos sensibles en prompts
- No registrar contenido confidencial
- Usar entornos aislados
- Mantener control de acceso a la carpeta `/db`

---

# 13. Errores Comunes

| Error | Causa | SoluciÃ³n |
|------|--------|----------|
| Ollama no arranca | Servicio detenido | `systemctl restart ollama` |
| Chroma no persiste | Falta `persist_directory` | AÃ±adir parÃ¡metro |
| RAG devuelve basura | Chunking incorrecto | Ajustar tamaÃ±o |
| Agente entra en loop | Herramientas mal definidas | AÃ±adir lÃ­mites |

---

# 14. Plantillas de Proyecto

```
project/
â”‚
â”œâ”€â”€ agents/
â”œâ”€â”€ chains/
â”œâ”€â”€ data/
â”œâ”€â”€ db/
â”œâ”€â”€ loaders/
â”œâ”€â”€ prompts/
â”œâ”€â”€ rag/
â””â”€â”€ main.py
```

---

# 15. ApÃ©ndices

## 15.1 Glosario

- **LLM**: Large Language Model
- **RAG**: Retrieval-Augmented Generation
- **Embedding**: Vector numÃ©rico que representa texto
- **Vector Store**: Base de datos para embeddings

## 15.2 Cheatsheet

- `ChatOllama` â†’ LLM local
- `OllamaEmbeddings` â†’ Embeddings locales
- `Chroma` â†’ Vector store
- `RetrievalQA` â†’ RAG listo para usar

---